{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import VGG16, Xception, InceptionV3, MobileNet, ResNet50\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4076 images belonging to 101 classes.\n",
      "Found 1078 images belonging to 101 classes.\n",
      "Found 1299 images belonging to 101 classes.\n",
      "128.0\n",
      "34.0\n",
      "1299.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "shape = (224, 224)\n",
    "\n",
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=True, \n",
    "    width_shift_range=0.1, \n",
    "    height_shift_range=0.2, \n",
    "    rotation_range=10, \n",
    "    zoom_range=0.05, \n",
    "    brightness_range=[0.4, 0.8],\n",
    "    fill_mode=\"reflect\"\n",
    "    ) \n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=\"subset_images/train\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    seed=2019)\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    directory=\"subset_images/valid\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    seed=2019)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    directory=\"subset_images/test\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# create step size\n",
    "STEP_SIZE_TRAIN=np.ceil(train_generator.n/train_generator.batch_size)\n",
    "STEP_SIZE_VALID=np.ceil(valid_generator.n/valid_generator.batch_size)\n",
    "STEP_SIZE_TEST=np.ceil(test_generator.n/test_generator.batch_size)\n",
    "\n",
    "print(STEP_SIZE_TRAIN)\n",
    "print(STEP_SIZE_VALID)\n",
    "print(STEP_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(shape[0], shape[1], 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(shape[0], shape[1], 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.0001, decay=1e-6),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "earlyStopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0, mode=\"min\")\n",
    "checkpoint = ModelCheckpoint(os.path.join(\"models\", \"model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), verbose=1, \n",
    "                             monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missinglink\n",
    "missinglink_callback = missinglink.KerasCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit base model\n",
    "model.fit(train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=[missinglink_callback,earlyStopping, checkpoint, reduce_lr_loss],\n",
    "                    epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning => MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base MobileNet\n",
    "base_mn = MobileNet(weights='imagenet', include_top=False, input_shape=(shape[0], shape[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_block = base_mn.output\n",
    "\n",
    "top_block = GlobalAveragePooling2D()(top_block) # pool over height/width to reduce number of parameters\n",
    "top_block = Dense(256, activation='relu')(top_block) # add a Dense layer\n",
    "predictions = Dense(num_classes, activation='softmax')(top_block) # add another Dense layer\n",
    "mn_transfer = Model(inputs=base_mn.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze last few layers\n",
    "for i, layer in enumerate(reversed(mn_transfer.layers)):\n",
    "    layer.trainable = True\n",
    "    if i > 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_transfer.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.0002),\n",
    "              metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 128.0 steps, validate for 34.0 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dineshp/.pyenv/versions/3.7.6/lib/python3.7/site-packages/missinglink_kernel/callback/dispatchers/json_encoder.py:24: UserWarning: skipped MissingLinkJsonEncoder because of TypeError Object of type ResourceVariable is not JSON serializable\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "127/128 [============================>.] - ETA: 5s - loss: 0.0181 - acc: 0.9955 \n",
      "Epoch 00001: val_loss improved from inf to 1.50657, saving model to models/keras_models/model-mobilenet-RMSprop0.0002-001-0.995584-0.670686.h5\n",
      "128/128 [==============================] - 803s 6s/step - loss: 0.0181 - acc: 0.9956 - val_loss: 1.5066 - val_acc: 0.6707\n",
      "Epoch 2/20\n",
      "127/128 [============================>.] - ETA: 7s - loss: 0.0188 - acc: 0.9943 \n",
      "Epoch 00002: val_loss improved from 1.50657 to 1.49776, saving model to models/keras_models/model-mobilenet-RMSprop0.0002-002-0.994357-0.675325.h5\n",
      "128/128 [==============================] - 995s 8s/step - loss: 0.0187 - acc: 0.9944 - val_loss: 1.4978 - val_acc: 0.6753\n",
      "Epoch 3/20\n",
      "127/128 [============================>.] - ETA: 6s - loss: 0.0169 - acc: 0.9955 \n",
      "Epoch 00003: val_loss improved from 1.49776 to 1.40099, saving model to models/keras_models/model-mobilenet-RMSprop0.0002-003-0.995584-0.674397.h5\n",
      "128/128 [==============================] - 818s 6s/step - loss: 0.0168 - acc: 0.9956 - val_loss: 1.4010 - val_acc: 0.6744\n",
      "Epoch 4/20\n",
      "127/128 [============================>.] - ETA: 4s - loss: 0.0136 - acc: 0.9973\n",
      "Epoch 00004: val_loss did not improve from 1.40099\n",
      "128/128 [==============================] - 651s 5s/step - loss: 0.0136 - acc: 0.9973 - val_loss: 1.5376 - val_acc: 0.6716\n",
      "Epoch 5/20\n",
      "127/128 [============================>.] - ETA: 5s - loss: 0.0170 - acc: 0.9955 \n",
      "Epoch 00005: val_loss did not improve from 1.40099\n",
      "128/128 [==============================] - 695s 5s/step - loss: 0.0169 - acc: 0.9956 - val_loss: 1.4622 - val_acc: 0.6892\n",
      "Epoch 6/20\n",
      "127/128 [============================>.] - ETA: 5s - loss: 0.0197 - acc: 0.9948 \n",
      "Epoch 00006: val_loss did not improve from 1.40099\n",
      "128/128 [==============================] - 732s 6s/step - loss: 0.0196 - acc: 0.9948 - val_loss: 1.4405 - val_acc: 0.6846\n",
      "Epoch 7/20\n",
      "127/128 [============================>.] - ETA: 5s - loss: 0.0172 - acc: 0.9955 \n",
      "Epoch 00007: val_loss did not improve from 1.40099\n",
      "128/128 [==============================] - 745s 6s/step - loss: 0.0173 - acc: 0.9953 - val_loss: 1.7654 - val_acc: 0.6633\n",
      "Epoch 8/20\n",
      "127/128 [============================>.] - ETA: 5s - loss: 0.0155 - acc: 0.9948 \n",
      "Epoch 00008: val_loss did not improve from 1.40099\n",
      "128/128 [==============================] - 759s 6s/step - loss: 0.0155 - acc: 0.9948 - val_loss: 1.6414 - val_acc: 0.6781\n",
      "Epoch 9/20\n",
      "127/128 [============================>.] - ETA: 4s - loss: 0.0152 - acc: 0.9963\n",
      "Epoch 00009: val_loss did not improve from 1.40099\n",
      "128/128 [==============================] - 671s 5s/step - loss: 0.0152 - acc: 0.9963 - val_loss: 1.6901 - val_acc: 0.6698\n",
      "Epoch 10/20\n",
      "127/128 [============================>.] - ETA: 5s - loss: 0.0157 - acc: 0.9955 \n",
      "Epoch 00010: val_loss did not improve from 1.40099\n",
      "128/128 [==============================] - 747s 6s/step - loss: 0.0156 - acc: 0.9956 - val_loss: 1.6898 - val_acc: 0.6716\n",
      "Epoch 11/20\n",
      "127/128 [============================>.] - ETA: 5s - loss: 0.0093 - acc: 0.9980 \n",
      "Epoch 00011: val_loss did not improve from 1.40099\n",
      "128/128 [==============================] - 756s 6s/step - loss: 0.0092 - acc: 0.9980 - val_loss: 1.5618 - val_acc: 0.7022\n",
      "Epoch 12/20\n",
      "127/128 [============================>.] - ETA: 5s - loss: 0.0099 - acc: 0.9968 \n",
      "Epoch 00012: val_loss did not improve from 1.40099\n",
      "128/128 [==============================] - 764s 6s/step - loss: 0.0098 - acc: 0.9968 - val_loss: 1.7039 - val_acc: 0.6763\n",
      "Epoch 13/20\n",
      "127/128 [============================>.] - ETA: 5s - loss: 0.0116 - acc: 0.9975 \n",
      "Epoch 00013: val_loss did not improve from 1.40099\n",
      "128/128 [==============================] - 722s 6s/step - loss: 0.0116 - acc: 0.9975 - val_loss: 1.5809 - val_acc: 0.6846\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "checkpoint3 = ModelCheckpoint(os.path.join(\"models\",\"keras_models\", \"model-mobilenet-RMSprop0.0002-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), \n",
    "                              verbose=1, monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "history_mn = mn_transfer.fit(train_generator,\n",
    "                                       steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                       validation_data=valid_generator,\n",
    "                                       validation_steps=STEP_SIZE_VALID,\n",
    "                                       callbacks=[missinglink_callback,earlyStopping, checkpoint3],\n",
    "                                       epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "#model-mobilenet-RMSprop0.0002-001-0.930507-0.647776.h5\n",
    "transfer = load_model(os.path.join(\"models\",\"keras_models\", \"model-mobilenet-RMSprop0.0002-002-0.994357-0.675325.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "transfer.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=SGD(lr=0.0001), \n",
    "              metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 128.0 steps, validate for 34.0 steps\n"
     ]
    }
   ],
   "source": [
    "# continue fitting\n",
    "checkpoint3 = ModelCheckpoint(os.path.join(\"models\", \"keras_models\", \"model-mobilenet-RMSprop0.0002to0.0001-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), \n",
    "                              verbose=1, monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "history_mn = transfer.fit(train_generator,\n",
    "                                       steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                       validation_data=valid_generator,\n",
    "                                       validation_steps=STEP_SIZE_VALID,\n",
    "                                       callbacks=[missinglink_callback,earlyStopping, checkpoint3],\n",
    "                                       epochs=10, verbose=1, initial_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "val_loss, val_acc = transfer.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID, verbose=1)\n",
    "print(\"Val Loss: {} \\nVal Accuracy: {}\".format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test images\n",
    "test_generator.reset()\n",
    "pred = transfer.predict(test_generator, steps=STEP_SIZE_TEST, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean predictions\n",
    "predictions = pred.argmax(axis=-1)\n",
    "labels = (test_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predicted_labels = [labels[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction dataframe\n",
    "filenames = test_generator.filenames\n",
    "correct_labels = [filename[:filename.find(\"/\")] for filename in filenames]\n",
    "results = pd.DataFrame({\"Filename\": filenames, \"Labels\": correct_labels, \"Predicted Label\": predicted_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots the distribution of the predictions for a given dish\n",
    "\n",
    "\n",
    "def plot_predictions_for_class(data, class_id, figsize=(10,7)):\n",
    "   \n",
    "    subset = data[data[\"Labels\"] == class_id]\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(\"Count per Predicted Label\")\n",
    "    plt.xlabel(\"Food Item\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    value_counts = subset[\"Predicted Label\"].value_counts().plot(kind=\"bar\")\n",
    "    return value_counts\n",
    "\n",
    "## Returns top k most accurate predictions\n",
    "    \n",
    "def get_most_accurate(data, k=1):\n",
    "\n",
    "    subset = data[data[\"Labels\"]==data[\"Predicted Label\"]]\n",
    "    results = (subset[\"Labels\"].value_counts()/data[\"Labels\"].value_counts()).sort_values(ascending=False)[:k]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_accurate(results,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_for_class(results, \"apple pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 1 image\n",
    "source = \"valid\"\n",
    "random_folder = np.random.choice(os.listdir(os.path.join(\"images\", source)))\n",
    "random_image = np.random.choice(os.listdir(os.path.join(\"images\", source, random_folder)))\n",
    "img = image.load_img(os.path.join( \"images\", source, random_folder, random_image), target_size = (shape[0], shape[1]))\n",
    "plt.imshow(img)\n",
    "img = image.img_to_array(img) / 255\n",
    "img = np.expand_dims(img, axis = 0)\n",
    "\n",
    "print(\"Actual:\", random_image)\n",
    "print(\"Predicted:\", labels[transfer.predict(img).argmax(axis=-1)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = transfer.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
